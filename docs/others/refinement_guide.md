# ğŸ”„ ë°˜ë³µì  ë°ì´í„° ì •ì œ í”„ë¡œì„¸ìŠ¤ ê°€ì´ë“œ

> **ê°ì„± ë¶„ì„ ë°ì´í„°ì…‹ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ Self-Supervised Learning ê°€ì´ë“œ**

## ğŸ¯ ì •ì œ í”„ë¡œì„¸ìŠ¤ ê°œìš”

ë°˜ë³µì  ë°ì´í„° ì •ì œëŠ” **ì•™ìƒë¸” ëª¨ë¸ì˜ ê³ ì‹ ë¢°ë„ ì˜ˆì¸¡ì„ í™œìš©í•˜ì—¬ ë°ì´í„°ì…‹ì˜ ë¼ë²¨ì„ ì§€ì†ì ìœ¼ë¡œ ê°œì„ **í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ë™ì‹œì— ê°ì„±ì‚¬ì „ë„ ì§„í™”ì‹œì¼œ ì „ì²´ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ“Š ì •ì œ ë‹¨ê³„ë³„ ìƒì„¸ ì„¤ëª…

### **Step 1: ì´ˆê¸° ëª¨ë¸ í›ˆë ¨** ğŸ
```
ì›ë³¸ ë°ì´í„° â†’ ê¸°ë³¸ ëª¨ë¸ í›ˆë ¨ â†’ ì´ˆê¸° ì„±ëŠ¥ ë² ì´ìŠ¤ë¼ì¸ ì„¤ì •
```

#### **1.1 LSTM ëª¨ë¸ (CPU ìµœì í™”)**
```bash
python src/training/train_lstm_cpu.py
```

**ì„¤ì • ë§¤ê°œë³€ìˆ˜**:
- ë°°ì¹˜ í¬ê¸°: 512 (32GB RAM ìµœì í™”)
- ì‹œí€€ìŠ¤ ê¸¸ì´: 128 í† í°
- ì„ë² ë”© ì°¨ì›: 200
- LSTM ìœ ë‹›: 128
- ë“œë¡­ì•„ì›ƒ: 0.3
- ì—í¬í¬: 25

**ì˜ˆìƒ ì„±ëŠ¥**: ì •í™•ë„ 85-88%

#### **1.2 BiLSTM ëª¨ë¸ (PyTorch)**
```bash
python src/training/train_bilstm_pytorch.py
```

**ì„¤ì • ë§¤ê°œë³€ìˆ˜**:
- ë°°ì¹˜ í¬ê¸°: 256 (ë©€í‹°í”„ë¡œì„¸ì‹± ê³ ë ¤)
- ì–‘ë°©í–¥ LSTM: 64 Ã— 2
- ì›Œì»¤ í”„ë¡œì„¸ìŠ¤: 4ê°œ
- í•™ìŠµë¥ : 0.001 â†’ 0.0001 (ìŠ¤ì¼€ì¤„ë§)

**ì˜ˆìƒ ì„±ëŠ¥**: ì •í™•ë„ 87-90%

#### **1.3 Word Sentiment ëª¨ë¸**
- ê°ì„±ì‚¬ì „ ê¸°ë°˜ í†µê³„ ëª¨ë¸
- í’ˆì‚¬ íƒœê¹… í™œìš© (ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ ì¤‘ì‹¬)
- ë¬¸ë§¥ ê³ ë ¤ ê°ì„± ì ìˆ˜ ê³„ì‚°
- **ë‹¨ì–´ì˜ ì•ë’¤ ë¬¸ë§¥(ë¶€ì •ì–´, ê°•ì¡°ì–´, N-ê·¸ë¨ ë“±)ì„ ê³ ë ¤í•˜ì—¬ ê°ì„± ì ìˆ˜ë¥¼ ì¡°ì •í•˜ê³ , ìˆ™ë°•ì—…ì†Œ ë„ë©”ì¸ íŠ¹í™” ì–´íœ˜ ë° ê·œì¹™ ë°˜ì˜ (ì˜ˆ: 'ì²´í¬ì¸', 'ì–´ë©”ë‹ˆí‹°', 'ìˆ˜ì••' ë“±)**

**ì˜ˆìƒ ì„±ëŠ¥**: ì •í™•ë„ 75-80%

#### **1.4 BERT ëª¨ë¸ (ë°±ê·¸ë¼ìš´ë“œ)**
- GPU í™œìš© ë”¥ëŸ¬ë‹ ëª¨ë¸
- ì‚¬ì „ í›ˆë ¨ëœ í•œêµ­ì–´ BERT í™œìš©
- í˜„ì¬ 3/10 ì—í¬í¬ ì§„í–‰ ì¤‘

**ì˜ˆìƒ ì„±ëŠ¥**: ì •í™•ë„ 92-95%

---

### **Step 2: ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„±** ğŸ¤–

#### **2.1 ëª¨ë¸ ê°€ì¤‘ì¹˜ ì„¤ì •**
```python
model_weights = {
    'lstm': 0.25,           # ê¸°ë³¸ ì„±ëŠ¥
    'bilstm': 0.30,         # ì–‘ë°©í–¥ ì„±ëŠ¥ ìš°ìˆ˜
    'word_sentiment': 0.20,  # í•´ì„ ê°€ëŠ¥ì„±
    'bert': 0.25            # ìµœê³  ì„±ëŠ¥ (ê°€ìš©ì‹œ)
}
```

#### **2.2 ì‹ ë¢°ë„ ê³„ì‚° ë°©ë²•**
```python
def calculate_confidence(predictions):
    # ëª¨ë¸ ê°„ í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„
    std_dev = np.std(predictions)
    confidence = 1.0 - min(std_dev * 2, 1.0)
    
    # ê·¹ë‹¨ê°’(0.9 ì´ìƒ, 0.1 ì´í•˜)ì— ë³´ë„ˆìŠ¤
    if max(predictions) > 0.9 or min(predictions) < 0.1:
        confidence *= 1.2
    
    return min(confidence, 1.0)
```

#### **2.3 ì˜ˆì¸¡ ê²°ê³¼ ì˜ˆì‹œ**
```
í…ìŠ¤íŠ¸: "ì •ë§ ì¢‹ì€ ì„œë¹„ìŠ¤ì˜€ì–´ìš”!"
LSTM ì˜ˆì¸¡: 0.85 (ê¸ì •)
BiLSTM ì˜ˆì¸¡: 0.89 (ê¸ì •)  
Word Sentiment: 0.78 (ê¸ì •)
BERT ì˜ˆì¸¡: 0.92 (ê¸ì •)

ì•™ìƒë¸” ì˜ˆì¸¡: 0.86 (ê¸ì •)
ì‹ ë¢°ë„: 0.91 (ë†’ìŒ) â† ëª¨ë¸ë“¤ì´ ì¼ì¹˜
```

---

### **Step 3: ê³ ì‹ ë¢°ë„ ë°ì´í„° í•„í„°ë§** ğŸ”

#### **3.1 ì‹ ë¢°ë„ ì„ê³„ê°’**
```python
CONFIDENCE_THRESHOLD = 0.7
high_confidence_data = predictions[predictions['confidence'] >= 0.7]
```

#### **3.2 í•„í„°ë§ í†µê³„ ì˜ˆì‹œ**
```
ì „ì²´ ë°ì´í„°: 387,566ê°œ
ê³ ì‹ ë¢°ë„ (â‰¥0.7): 310,053ê°œ (80.0%)
ì¤‘ì‹ ë¢°ë„ (0.5-0.7): 62,341ê°œ (16.1%)
ì €ì‹ ë¢°ë„ (<0.5): 15,172ê°œ (3.9%)

â†’ 80%ì˜ ê³ í’ˆì§ˆ ë°ì´í„°ë¡œ ë¼ë²¨ ì •ì œ ì§„í–‰
```

#### **3.3 ì‹ ë¢°ë„ ë¶„í¬ ë¶„ì„**
```python
confidence_stats = {
    'mean': 0.756,
    'std': 0.182,
    'min': 0.121,
    'max': 0.998,
    'q25': 0.634,
    'q50': 0.781,
    'q75': 0.897
}
```

---

### **Step 4: ë¼ë²¨ ë³´ì • í”„ë¡œì„¸ìŠ¤** âœï¸

#### **4.1 ë³´ì • ê¸°ì¤€**
```python
def should_correct_label(original, predicted, confidence):
    # ë†’ì€ ì‹ ë¢°ë„ + í° ì°¨ì´ = ë³´ì • ëŒ€ìƒ
    threshold = 0.3
    return (confidence >= 0.7 and 
            abs(original - predicted) >= threshold)
```

#### **4.2 ë³´ì • í†µê³„ ì¶”ì **
```python
correction_stats = {
    'total_samples': 387566,
    'corrected_samples': 15234,
    'correction_rate': 3.93,  # %
    'positive_to_negative': 2156,
    'negative_to_positive': 1987,
    'fine_tuning': 11091  # ë¯¸ì„¸ ì¡°ì •
}
```

#### **4.3 ë³´ì • ì‚¬ë¡€**
```
ì›ë³¸: "ì„œë¹„ìŠ¤ê°€ ê·¸ì € ê·¸ë˜ìš”" â†’ ë¼ë²¨: 0.8 (ê¸ì •)
ì•™ìƒë¸” ì˜ˆì¸¡: 0.3 (ë¶€ì •) â†’ ì‹ ë¢°ë„: 0.85
ë³´ì • ê²°ê³¼: 0.3 (ë¶€ì •) â† ëª…ë°±í•œ ì˜¤ë¼ë²¨ë§ ìˆ˜ì •
```

---

### **Step 5: ê°ì„±ì‚¬ì „ ì§„í™”** ğŸ“š

#### **5.1 ë‹¨ì–´ ì¶”ì¶œ ë° ë¶„ì„**
```python
def extract_words_with_context(text, sentiment, confidence):
    words = tokenize(text)
    return [{
        'word': word,
        'context': text,
        'sentiment': sentiment,
        'confidence': confidence,
        'position': position_in_text
    } for word in words if len(word) > 1]
```

#### **5.2 ë‹¨ì–´ ì¤‘ìš”ë„ ê³„ì‚°**
```python
def calculate_word_importance(word, contexts):
    frequency = len(contexts)                    # ì¶œí˜„ ë¹ˆë„
    avg_confidence = np.mean([c['confidence'] for c in contexts])  # í‰ê·  ì‹ ë¢°ë„
    consistency = 1.0 - np.std([c['sentiment'] for c in contexts])  # ì¼ê´€ì„±
    length_bonus = min(len(word) / 10, 1.0)     # ê¸¸ì´ ë³´ë„ˆìŠ¤
    
    importance = (frequency * 0.4 + 
                 avg_confidence * 0.3 + 
                 consistency * 0.2 + 
                 length_bonus * 0.1)
    return importance
```

#### **5.3 ì‚¬ì „ ì—…ë°ì´íŠ¸ ì•Œê³ ë¦¬ì¦˜**
```python
def update_word_score(old_score, new_score, importance):
    # ì¤‘ìš”ë„ì— ë”°ë¥¸ ì ì§„ì  ì—…ë°ì´íŠ¸
    alpha = 0.3 + 0.2 * importance  # 0.3~0.5 ë²”ìœ„
    updated_score = (1 - alpha) * old_score + alpha * new_score
    return updated_score
```

#### **5.4 ì‚¬ì „ ì§„í™” í†µê³„**
```
ë°˜ë³µ 1 ê²°ê³¼:
- ì—…ë°ì´íŠ¸ëœ ë‹¨ì–´: 12,456ê°œ
- ì‹ ê·œ ì¶”ê°€: 3,421ê°œ  
- ì œê±°ëœ ë‹¨ì–´: 892ê°œ
- ì´ ì‚¬ì „ í¬ê¸°: 47,231ê°œ
- í‰ê·  ì¤‘ìš”ë„: 0.634
```

---

### **Step 6: ìˆ˜ë ´ ê°ì§€** ğŸ¯

#### **6.1 ìˆ˜ë ´ ì¡°ê±´**
```python
def check_convergence(current_iter, previous_iter):
    # ë¼ë²¨ ë³€í™”ìœ¨ ê³„ì‚°
    label_changes = count_label_differences(current_iter, previous_iter)
    label_change_rate = label_changes / len(current_iter)
    
    # ì‚¬ì „ ë³€í™”ìœ¨ ê³„ì‚°
    dict_changes = count_dictionary_changes(current_iter, previous_iter)
    dict_change_rate = dict_changes / len(current_dictionary)
    
    # ìˆ˜ë ´ íŒì • (ë‘˜ ë‹¤ 5% ë¯¸ë§Œ)
    return (label_change_rate < 0.05 and dict_change_rate < 0.05)
```

#### **6.2 ìˆ˜ë ´ í†µê³„ ì˜ˆì‹œ**
```
ë°˜ë³µ 1 â†’ 2:
- ë¼ë²¨ ë³€í™”ìœ¨: 8.3% (ë¯¸ìˆ˜ë ´)
- ì‚¬ì „ ë³€í™”ìœ¨: 12.1% (ë¯¸ìˆ˜ë ´)

ë°˜ë³µ 2 â†’ 3:  
- ë¼ë²¨ ë³€í™”ìœ¨: 5.7% (ë¯¸ìˆ˜ë ´)
- ì‚¬ì „ ë³€í™”ìœ¨: 7.4% (ë¯¸ìˆ˜ë ´)

ë°˜ë³µ 3 â†’ 4:
- ë¼ë²¨ ë³€í™”ìœ¨: 3.2% (ìˆ˜ë ´)
- ì‚¬ì „ ë³€í™”ìœ¨: 2.8% (ìˆ˜ë ´)
â†’ ìˆ˜ë ´ ë‹¬ì„±! âœ…
```

---

## ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒ ì¶”ì 

### **ë°˜ë³µë³„ ì„±ëŠ¥ ì§€í‘œ**
```
ê¸°ë³¸ ëª¨ë¸ (ë°˜ë³µ 0):
- LSTM: 86.2%
- BiLSTM: 88.7%  
- Word Sentiment: 78.9%
- ì•™ìƒë¸”: 89.1%

ë°˜ë³µ 1 ì™„ë£Œ:
- LSTM: 87.8% (+1.6%)
- BiLSTM: 90.1% (+1.4%)
- Word Sentiment: 82.3% (+3.4%)
- ì•™ìƒë¸”: 91.2% (+2.1%)

ë°˜ë³µ 2 ì™„ë£Œ:
- LSTM: 88.9% (+1.1%)
- BiLSTM: 91.0% (+0.9%)
- Word Sentiment: 84.1% (+1.8%)
- ì•™ìƒë¸”: 92.4% (+1.2%)
```

### **ë°ì´í„° í’ˆì§ˆ ê°œì„ **
```
ë…¸ì´ì¦ˆ ë¼ë²¨ ê°ì†Œ:
- ì´ˆê¸°: 15.2% ì˜ëª»ëœ ë¼ë²¨
- ë°˜ë³µ 1: 11.8% (-3.4%)
- ë°˜ë³µ 2: 8.9% (-2.9%)
- ë°˜ë³µ 3: 6.7% (-2.2%)

ê°ì„±ì‚¬ì „ í’ˆì§ˆ:
- ì´ˆê¸°: í‰ê·  ì¼ê´€ì„± 0.65
- ë°˜ë³µ 1: 0.72 (+0.07)
- ë°˜ë³µ 2: 0.78 (+0.06)
- ë°˜ë³µ 3: 0.83 (+0.05)
```

---

## ğŸ”§ ìµœì í™” íŒ

### **ë©”ëª¨ë¦¬ ìµœì í™”**
```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²­í¬ ì²˜ë¦¬
CHUNK_SIZE = 10000
for chunk in pd.read_sql(query, conn, chunksize=CHUNK_SIZE):
    process_chunk(chunk)
    gc.collect()  # ë©”ëª¨ë¦¬ í•´ì œ
```

### **CPU í™œìš© ìµœì í™”**
```python
# ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ì˜ˆì¸¡ ë³‘ë ¬í™”
from multiprocessing import Pool
with Pool(processes=4) as pool:
    results = pool.map(predict_batch, data_chunks)
```

### **ë””ìŠ¤í¬ I/O ìµœì í™”**
```python
# SQLite ì„±ëŠ¥ íŠœë‹
conn.execute("PRAGMA cache_size = -65536")  # 64MB ìºì‹œ
conn.execute("PRAGMA synchronous = NORMAL")
conn.execute("PRAGMA journal_mode = WAL")
```

---

## ğŸš¨ ì£¼ì˜ì‚¬í•­ ë° ë¬¸ì œ í•´ê²°

### **ì¼ë°˜ì ì¸ ë¬¸ì œë“¤**

#### **1. ë©”ëª¨ë¦¬ ë¶€ì¡± (OOM)**
**ì¦ìƒ**: `MemoryError` ë˜ëŠ” ì‹œìŠ¤í…œ ë©ˆì¶¤
**í•´ê²°ì±…**:
```python
# ë°°ì¹˜ í¬ê¸° ë™ì  ì¡°ì •
if psutil.virtual_memory().percent > 85:
    current_batch_size = max(current_batch_size // 2, 32)
    print(f"ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸°ë¥¼ {current_batch_size}ë¡œ ê°ì†Œ")
```

#### **2. ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ**
**ì¦ìƒ**: 10íšŒ ë°˜ë³µ í›„ì—ë„ ë³€í™”ìœ¨ì´ ë†’ìŒ
**í•´ê²°ì±…**:
- ì‹ ë¢°ë„ ì„ê³„ê°’ ìƒí–¥ ì¡°ì • (0.7 â†’ 0.8)
- ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì¬ì¡°ì •
- ì´ìƒì¹˜ ë°ì´í„° ìˆ˜ë™ ê²€í† 

#### **3. ì‚¬ì „ í’ˆì§ˆ ì €í•˜**
**ì¦ìƒ**: ì¼ê´€ì„± ì ìˆ˜ ê°ì†Œ, ì´ìƒí•œ ë‹¨ì–´ ì¶”ê°€
**í•´ê²°ì±…**:
```python
# í’ˆì§ˆ í•„í„° ê°•í™”
MIN_CONTEXTS = 5      # ìµœì†Œ ì¶œí˜„ íšŸìˆ˜
MIN_CONSISTENCY = 0.7  # ìµœì†Œ ì¼ê´€ì„±
MIN_IMPORTANCE = 0.4   # ìµœì†Œ ì¤‘ìš”ë„
```

### **ëª¨ë‹ˆí„°ë§ ì•Œë¦¼**
```python
# ì´ìƒ ìƒí™© ìë™ ê°ì§€
def check_anomalies(stats):
    alerts = []
    
    if stats['memory_usage'] > 90:
        alerts.append("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ìœ„í—˜ ìˆ˜ì¤€")
    
    if stats['label_change_rate'] > 50:
        alerts.append("âš ï¸ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ ë¼ë²¨ ë³€í™”ìœ¨")
    
    if stats['avg_confidence'] < 0.5:
        alerts.append("âš ï¸ ì•™ìƒë¸” ì‹ ë¢°ë„ ì €í•˜")
    
    return alerts
```

---

## ğŸ¯ í’ˆì§ˆ ë³´ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### **ê° ë°˜ë³µ í›„ í™•ì¸ì‚¬í•­**
- [ ] **ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ **: 85% ì´í•˜ ìœ ì§€
- [ ] **ë¼ë²¨ ë³€í™”ìœ¨**: í•©ë¦¬ì  ë²”ìœ„ (1-20%)
- [ ] **ì‹ ë¢°ë„ ë¶„í¬**: í‰ê·  0.6 ì´ìƒ
- [ ] **ì‚¬ì „ ì¼ê´€ì„±**: 0.7 ì´ìƒ ìœ ì§€
- [ ] **ëª¨ë¸ ì„±ëŠ¥**: ì´ì „ ëŒ€ë¹„ ë™ë“± ì´ìƒ

### **ìµœì¢… ì™„ë£Œ ì‹œ ê²€ì¦**
- [ ] **ìˆ˜ë ´ ë‹¬ì„±**: ë¼ë²¨ + ì‚¬ì „ ë³€í™”ìœ¨ < 5%
- [ ] **ì„±ëŠ¥ í–¥ìƒ**: ì´ˆê¸° ëŒ€ë¹„ 3% ì´ìƒ ê°œì„ 
- [ ] **ë°ì´í„° ë¬´ê²°ì„±**: ê²°ì¸¡ê°’, ì´ìƒì¹˜ ì—†ìŒ
- [ ] **ì¬í˜„ì„±**: ë™ì¼ ê²°ê³¼ ì¬ìƒì‚° ê°€ëŠ¥
- [ ] **ë¬¸ì„œí™”**: ëª¨ë“  ë³€í™” ì´ë ¥ ê¸°ë¡

---

## ğŸ“Š ê²°ê³¼ í•´ì„ ê°€ì´ë“œ

### **ì„±ê³µì ì¸ ì •ì œì˜ ì§€í‘œ**
1. **ì§€ì†ì  ì„±ëŠ¥ í–¥ìƒ**: ë§¤ ë°˜ë³µë§ˆë‹¤ 1-3% ê°œì„ 
2. **ì•ˆì •ì  ìˆ˜ë ´**: 3-7íšŒ ë°˜ë³µ ë‚´ ìˆ˜ë ´ ë‹¬ì„±
3. **ê· í˜• ì¡íŒ ê°œì„ **: ëª¨ë“  ëª¨ë¸ì´ ê³ ë¥´ê²Œ í–¥ìƒ
4. **í’ˆì§ˆ ìˆëŠ” ì‚¬ì „**: ì¼ê´€ì„± 0.8 ì´ìƒ, ì¤‘ìš” ë‹¨ì–´ ë³´ì¡´

### **ë¬¸ì œê°€ ìˆëŠ” ê²½ìš°ì˜ ì‹ í˜¸**
1. **ì„±ëŠ¥ ì €í•˜**: íŠ¹ì • ë°˜ë³µì—ì„œ ì„±ëŠ¥ í•˜ë½
2. **ë¶ˆì•ˆì •í•œ ë³€í™”**: ë³€í™”ìœ¨ì´ ê³„ì† ì¦ê°€
3. **ì‚¬ì „ ì˜¤ì—¼**: ì´ìƒí•œ ë‹¨ì–´ë“¤ì´ ëŒ€ëŸ‰ ì¶”ê°€
4. **í¸í–¥ ì¦ê°€**: íŠ¹ì • í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡ ì§‘ì¤‘

---

*ì •ì œ í”„ë¡œì„¸ìŠ¤ ê°€ì´ë“œ ë²„ì „: 1.0*  
*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2025-07-17*
