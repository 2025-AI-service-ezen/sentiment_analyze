## 프로젝트 2: 점진적 자기지도학습 기반 데이터셋 정제 및 모델 재훈련 - 기술 요구사항 정의서 (TRD)

**문서 버전:** 1.0
**작성일:** 2025년 7월 21일
**작성자:** Gemini

### 1. 서론

본 문서는 감성 분석 앙상블 모델 프로젝트의 두 번째 하위 프로젝트인 "점진적 자기지도학습 기반 데이터셋 정제 및 모델 재훈련"에 대한 기술 요구사항을 정의합니다. 이 프로젝트는 프로젝트 1에서 구축된 베이스라인 모델들을 활용하여 데이터셋의 라벨을 지속적으로 개선하고, 이를 통해 모델 성능을 점진적으로 향상시키는 자기지도학습(Self-training) 기반의 MLOps 파이프라인을 구축하는 것을 목표로 합니다. [`PROJECT_2_PRD.md`](PROJECT_2_PRD.md) 및 [`PROJECT_2_TECHNICAL_SPECIFICATION.md`](PROJECT_2_TECHNICAL_SPECIFICATION.md)의 내용을 기반으로 작성되었습니다.

### 2. 시스템 아키텍처 개요

`PROJECT_2_TECHNICAL_SPECIFICATION.md`에 명시된 시스템 아키텍처를 따르며, 핵심 구성 요소는 SQLite 데이터베이스, 앙상블 예측 모듈, 라벨 보정 모듈, 순차적 모델 재훈련 모듈, MLflow 추적 시스템, 그리고 수렴 감지 및 확증 편향 완화 모듈을 포함합니다.

### 3. 기술 요구사항

#### 3.1. 데이터 로딩 및 앙상블 예측

*   **데이터 로딩:** SQLite 데이터베이스의 `sentences` 테이블에서 모든 문장 데이터를 청크(Chunk) 단위로 로드해야 합니다. `chunksize`는 시스템 메모리 및 처리 효율성을 고려하여 동적으로 또는 설정 파일에서 관리되어야 합니다.
*   **멀티프로세싱 예측:** 로드된 각 데이터 청크에 대해 프로젝트 1에서 학습된 4개 모델(Word Sentiment, LSTM, BiLSTM, BERT)을 활용하여 감성 예측을 수행해야 합니다. 이 과정은 `multiprocessing.Pool`을 사용하여 병렬 처리되어야 합니다.
*   **앙상블 예측:** 각 모델의 예측 결과를 통합하여 최종 앙상블 예측을 생성해야 합니다. 앙상블 로직은 `refinement_guide.md`에 명시된 가중치 및 신뢰도 계산 방법을 따라야 합니다.

#### 3.2. 신뢰도 기반 라벨 보정

*   **신뢰도 계산:** 앙상블 예측 결과에 대한 신뢰도를 계산해야 합니다. 신뢰도 계산 로직은 `refinement_guide.md`를 참조합니다.
*   **라벨 보정:** 계산된 신뢰도가 일정 임계값(예: 0.7) 이상인 예측에 대해 `sentences` 테이블의 `current_label`을 업데이트해야 합니다. `label_last_updated` 타임스탬프도 갱신되어야 합니다.
*   **벌크 업데이트:** SQLite 데이터베이스에 대한 라벨 업데이트는 `executemany()`와 같은 벌크 삽입/업데이트 기능을 사용하여 효율적으로 수행되어야 합니다.

#### 3.3. 모델 재훈련

*   **데이터셋 준비:** 라벨이 보정된 `sentences` 테이블의 전체 데이터를 기반으로 각 모델의 재훈련을 위한 데이터셋을 준비해야 합니다.
*   **순차적 학습:** `retraining_strategy_report.md`에 명시된 순서(Word Sentiment -> LSTM -> BiLSTM -> BERT)에 따라 각 모델을 순차적으로 재훈련해야 합니다.
*   **모델별 전략:** 각 모델은 `retraining_strategy_report.md`에 정의된 최적의 재훈련 전략(파인튜닝, 부분 재훈련, 전이 학습, 점진적 사전 업데이트)을 따라야 합니다.
*   **GPU 자원 관리:** 각 모델 학습 전 GPU 메모리를 초기화(`torch.cuda.empty_cache()`, `tf.keras.backend.clear_session()`)하고, 동적 배치 사이즈 조절 로직을 구현하여 OOM을 방지하고 GPU 활용률을 극대화해야 합니다.

#### 3.4. 수렴 감지 및 확증 편향 완화

*   **수렴 지표:** `refinement_guide.md`에 명시된 라벨 변화율 및 감성 사전 변화율을 주요 수렴 지표로 계산하고 추적해야 합니다.
*   **확증 편향 완화:**
    *   **신뢰도 임계값 조정:** 자기지도학습 루프가 진행됨에 따라 신뢰도 임계값을 점진적으로 높이는 로직을 구현해야 합니다.
    *   **LLM 활용:** `gemini-2.5-flash` 모델을 활용하여 앙상블 모델의 신뢰도가 낮은 샘플의 재라벨링, 앙상블 모델의 정성적 평가, 데이터셋 및 모델의 편향 감지 및 완화에 기여해야 합니다. 이 과정에서 분당 호출 제한(RPM) 및 토큰 제한(TPM)을 최대한 활용하여 비용 효율적인 사용을 지향해야 합니다.

#### 3.5. MLflow 통합

*   **실험 추적:** 각 재훈련 반복(iteration)마다 데이터 정제 통계, 모델 성능 변화(정확도, 손실 등), 수렴 지표, 사용된 하이퍼파라미터 등을 MLflow에 기록해야 합니다.
*   **모델 버전 관리:** 재훈련을 통해 성능이 개선된 각 모델의 최신 버전을 MLflow Model Registry에 등록해야 합니다. 이 때, 모델의 `stage` (예: `Staging`, `Production`)를 적절히 관리하여 프로젝트 3에서 최신 모델을 자동으로 로드할 수 있도록 해야 합니다.

#### 3.6. DVC 통합

*   **데이터셋 버전 관리:** 라벨이 보정된 `sentences` 테이블의 데이터셋 스냅샷을 DVC를 통해 버전 관리해야 합니다. 각 재훈련 반복마다 새로운 데이터셋 버전을 생성하고 태그를 지정해야 합니다.

### 4. 구현 세부 사항

*   **파이프라인 오케스트레이션:** 자기지도학습 루프의 각 단계(데이터 로딩, 예측, 라벨 보정, 재훈련, 수렴 감지)는 파이썬 스크립트 또는 간단한 워크플로우 관리 도구를 통해 순차적으로 실행되어야 합니다.
*   **오류 처리:** 각 단계에서 발생할 수 있는 오류(예: DB 연결 실패, 모델 로딩 실패, GPU 메모리 부족)에 대한 견고한 예외 처리 로직을 구현하고, 상세한 로그를 기록해야 합니다.
*   **로깅:** 모든 중요한 작업 및 결과는 구조화된 로깅(예: JSON 형식)을 사용하여 기록되어야 합니다.

### 5. 테스트 전략

*   **단위 테스트:** 각 모듈(데이터 로딩, 예측, 라벨 보정, 모델 학습 스크립트)에 대한 단위 테스트를 작성합니다.
*   **통합 테스트:** 자기지도학습 루프의 전체 파이프라인이 예상대로 작동하는지, MLflow 및 DVC와의 통합이 올바른지 확인하는 통합 테스트를 수행합니다.
*   **성능 테스트:** 대용량 데이터셋 처리 및 모델 재훈련 시 CPU/GPU 자원 활용률, 메모리 사용량, 실행 시간 등을 측정하여 성능 병목을 식별하고 최적화합니다.
*   **회귀 테스트:** 재훈련된 모델이 이전 버전의 모델보다 성능이 저하되지 않았는지 확인하는 회귀 테스트를 수행합니다.

### 6. 배포 고려사항

*   **MLflow 서버:** MLflow 추적 서버 및 모델 레지스트리는 별도의 서버에 배포되어야 합니다.
*   **컨테이너화:** 자기지도학습 파이프라인의 각 구성 요소(예: 데이터 처리 스크립트, 모델 학습 스크립트)는 Docker 컨테이너로 패키징되어 배포 및 확장을 용이하게 할 수 있습니다.
*   **자동화:** 주기적인 재훈련을 위한 스케줄링(예: Cron Job, Airflow)을 고려해야 합니다.
