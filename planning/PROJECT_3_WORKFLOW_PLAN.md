## 프로젝트 3: 앙상블 모델 기반 감성 분석 API 서비스 - 워크플로우 계획

**문서 버전:** 1.0
**작성일:** 2025년 7월 21일
**작성자:** Gemini

### 1. 프로젝트 개요

본 문서는 감성 분석 앙상블 모델 프로젝트의 세 번째 하위 프로젝트인 "앙상블 모델 기반 감성 분석 API 서비스"에 대한 워크플로우 계획을 정의합니다. 이 프로젝트는 프로젝트 2에서 점진적으로 완성되는 최신 감성 분석 앙상블 모델을 외부 시스템에 안정적이고 확장 가능한 RESTful API 형태로 제공하며, 모델 업데이트 시 서비스 중단 없이 자동으로 최신 모델을 반영하는 것을 목표로 합니다.

### 2. 워크플로우 단계

#### Phase 1: API 서비스 설정 (API Service Setup)

*   **목표:** FastAPI 기반의 감성 분석 API 서비스를 구현하고 초기 모델 로딩 기능을 설정합니다.
*   **작업:**
    *   FastAPI 서비스를 구현하고 `POST /predict` 엔드포인트를 정의합니다.
    *   Pydantic을 사용하여 API 입력 데이터에 대한 유효성 검사를 통합합니다.
    *   MLflow Model Registry에서 최신 앙상블 모델을 초기 로드하는 기능을 구현합니다.
*   **예상 산출물:** 기본 API 서비스 코드, 초기 모델 로딩 기능.
*   **주요 도구:** Python 스크립트 (FastAPI, Pydantic, MLflow Client API).

#### Phase 2: 모델 핫스왑 구현 (Model Hot-swapping Implementation)

*   **목표:** 서비스 중단 없이 모델을 자동으로 업데이트하는 핫스왑 메커니즘을 구현합니다.
*   **작업:**
    *   MLflow Model Registry에서 새로운 모델 버전을 모니터링하는 백그라운드 스레드 또는 스케줄러를 구현합니다.
    *   새로운 모델 버전이 감지되면, 현재 서비스 중인 모델에 영향을 주지 않고 새로운 모델을 메모리에 로드하는 로직을 구현합니다.
    *   새로운 모델 로드가 완료되면, API 서비스의 예측 로직이 새로운 모델 인스턴스를 사용하도록 원자적으로 포인터를 전환하는 메커니즘을 구현합니다.
    *   이전 모델 인스턴스가 더 이상 사용되지 않을 때 메모리에서 안전하게 해제하는 로직을 구현합니다.
*   **예상 산출물:** 모델 핫스왑 기능이 통합된 API 서비스 코드.
*   **주요 도구:** Python (threading 또는 APScheduler), MLflow Client API.

#### Phase 3: 모니터링 및 컨테이너화 (Monitoring and Containerization)

*   **목표:** API 서비스의 주요 지표를 모니터링하고, 배포 일관성을 위해 서비스를 컨테이너화합니다.
*   **작업:**
    *   Prometheus 클라이언트 라이브러리를 사용하여 API 요청 수, 응답 시간, 오류율 등 핵심 메트릭을 노출합니다.
    *   FastAPI 애플리케이션을 컨테이너화하기 위한 Dockerfile을 작성합니다.
    *   (선택 사항) Prometheus 및 Grafana를 설정하여 서비스 메트릭을 수집하고 시각화합니다.
*   **예상 산출물:** 모니터링 기능이 추가된 API 서비스 코드, Dockerfile.
*   **주요 도구:** Python (prometheus_client), Docker.
