## 프로젝트 2: 점진적 자기지도학습 기반 데이터셋 정제 및 모델 재훈련 - 제품 요구사항 정의서 (PRD)

**문서 버전:** 1.0
**작성일:** 2025년 7월 18일
**작성자:** Gemini

### 1. 서론

본 문서는 감성 분석 앙상블 모델 프로젝트의 두 번째 하위 프로젝트인 "점진적 자기지도학습 기반 데이터셋 정제 및 모델 재훈련"에 대한 제품 요구사항을 정의합니다. 이 프로젝트는 프로젝트 1에서 구축된 베이스라인 모델들을 활용하여 데이터셋의 라벨을 지속적으로 개선하고, 이를 통해 모델 성능을 점진적으로 향상시키는 MLOps 파이프라인을 구축하는 것을 목표로 합니다. 이 문서는 [`PROJECT_OVERVIEW.md`](PROJECT_OVERVIEW.md)에 명시된 프로젝트의 목표와 범위를 기반으로 합니다.

### 2. 프로젝트 목표

*   **데이터셋 라벨 품질 향상:** 프로젝트 1에서 초기 5단계 감성 라벨링된 전체 숙박업소 리뷰 데이터셋의 라벨을 앙상블 모델의 고신뢰도 예측을 기반으로 검증하고, 부정확한 라벨을 수정하여 데이터셋의 품질을 극대화합니다. 특히 숙박업소 리뷰의 다차원적 감성(청결, 서비스, 위치 등)을 고려하여 라벨을 정제합니다.
*   **모델 성능 점진적 극대화:** 정제된 고품질 데이터셋으로 4개 감성 분석 모델(Word Sentiment, LSTM, BiLSTM, BERT)을 반복적으로 재훈련하여 각 모델 및 앙상블 모델의 성능을 지속적으로 향상시킵니다.
*   **자기지도학습 루프의 효율성 및 안정성 확보:** 멀티코어 CPU 및 GPU 자원을 최대한 활용하여 대용량 데이터 처리 및 모델 재훈련 과정을 효율적으로 수행하고, 자기지도학습의 확증 편향(Confirmation Bias) 문제를 방지하는 견고한 시스템을 구축합니다.

### 3. 사용자 스토리 및 사용 사례

*   **데이터 과학자/ML 엔지니어:**
    *   "나는 초기 데이터셋의 임시 라벨이 부정확할 수 있다는 문제를 해결하고, 모델의 예측을 활용하여 데이터셋의 라벨을 자동으로 정제하고 싶다."
    *   "나는 정제된 데이터셋으로 모델을 재훈련하여 성능을 지속적으로 개선하고 싶다."
    *   "나는 대용량 데이터셋을 효율적으로 처리하고, GPU 자원을 최대한 활용하여 모델 재훈련 시간을 단축하고 싶다."
    *   "나는 자기지도학습 과정에서 발생할 수 있는 확증 편향 문제를 인지하고, 이를 방지하기 위한 전략이 시스템에 적용되기를 원한다."
    *   "나는 데이터셋의 각 정제 버전과 재훈련된 모델의 성능 변화를 체계적으로 추적하고 싶다."

### 4. 기능 요구사항 (Functional Requirements)

*   **데이터 정제 파이프라인:**
    *   SQLite DB에 저장된 모든 문장 데이터를 청크(Chunk) 단위로 효율적으로 로드할 수 있어야 합니다.
    *   프로젝트 1에서 학습된 4개 모델(Word Sentiment, LSTM, BiLSTM, BERT)을 활용하여 각 문장의 감성을 예측하고, 앙상블 예측 결과를 생성해야 합니다.
    *   앙상블 예측 결과의 신뢰도를 계산하고, 일정 임계값 이상의 신뢰도를 가진 예측을 기반으로 `sentences` 테이블의 `current_label`을 업데이트해야 합니다.
    *   업데이트된 라벨은 `label_last_updated` 타임스탬프를 갱신해야 합니다.
    *   정제된 데이터셋은 DVC를 통해 버전을 관리해야 합니다.
*   **모델 재훈련 파이프라인:**
    *   정제된 전체 데이터셋을 활용하여 4개 모델을 재훈련할 수 있어야 합니다.
    *   여러 모델을 동시에 학습시키지 않고, GPU 자원을 최대한 활용하여 순차적으로 모델을 학습해야 합니다.
    *   `retraining_strategy_report.md`에 명시된 각 모델별 최적 재훈련 전략(BERT 파인튜닝, BiLSTM 부분 재훈련, LSTM 전이학습, Word Sentiment 점진적 사전 업데이트)을 적용해야 합니다.
*   **자기지도학습 루프 관리:**
    *   라벨 변화율 및 감성 사전 변화율을 주요 지표로 활용하여 데이터 정제 및 모델 재훈련 루프의 수렴 여부를 판단해야 합니다.
    *   확증 편향 완화를 위해 신뢰도 임계값의 점진적 조정, 주기적인 수동 검토 프로세스, 다양한 앙상블 기법 적용, 데이터 증강 전략을 포함해야 합니다.
    *   **Gemini API (gemini-2.5-flash)를 활용하여 앙상블 모델의 신뢰도가 낮은 샘플의 재라벨링, 앙상블 모델의 정성적 평가, 데이터셋 및 모델의 편향 감지 및 완화에 기여해야 합니다. 이 과정에서 분당 호출 제한(RPM) 및 토큰 제한(TPM)을 최대한 활용하여 비용 효율적인 사용을 지향해야 합니다.**
*   **실험 관리:**
    *   MLflow를 사용하여 재훈련 과정의 모든 실험 정보(데이터 정제 통계, 모델 성능 변화, 수렴 지표)를 기록하고 관리해야 합니다.

### 5. 비기능 요구사항 (Non-Functional Requirements)

*   **성능:**
    *   대용량 데이터셋(수십만 건 이상)의 로딩, 예측, 라벨 업데이트 과정이 멀티코어 CPU 및 GPU 자원을 효율적으로 활용하여 합리적인 시간 내에 완료되어야 합니다.
    *   모델 재훈련 과정은 GPU 자원을 최대한 활용하여 학습 시간을 최소화해야 합니다.
*   **확장성:**
    *   향후 데이터셋 규모 증가 및 모델 추가에 유연하게 대응할 수 있는 아키텍처를 가져야 합니다.
*   **신뢰성:**
    *   자기지도학습 루프가 안정적으로 작동하며, 확증 편향으로 인한 성능 저하를 방지해야 합니다.
    *   GPU 메모리 부족(OOM)과 같은 자원 관련 문제를 효과적으로 관리해야 합니다.
*   **재현성:**
    *   정제된 데이터셋의 각 버전과 재훈련된 모델은 DVC 및 MLflow를 통해 완벽하게 재현 가능해야 합니다.
*   **유지보수성:**
    *   모듈화된 코드 구조와 명확한 문서화를 통해 시스템의 유지보수 및 개선이 용이해야 합니다.
*   **하드웨어 호환성:**
    *   GTX 960, GTX 1070, GTX 1080Ti 등 다양한 NVIDIA GPU 환경에서 안정적으로 작동해야 합니다.

### 6. 범위 (Scope)

*   **포함 범위:**
    *   SQLite DB에 저장된 전체 문장 데이터 로딩 및 앙상블 예측
    *   신뢰도 기반 라벨 보정 및 DB 업데이트
    *   정제된 데이터셋의 DVC 버전 관리
    *   4개 모델의 재훈련 (순차적 GPU 활용)
    *   자기지도학습 루프의 수렴 감지 및 확증 편향 완화 전략 구현
    *   MLflow를 통한 재훈련 과정 실험 추적
*   **제외 범위:**
    *   초기 데이터 통합 및 베이스라인 모델 학습 (프로젝트 1)
    *   앙상블 모델 기반 감성 분석 API 서비스 구축 (프로젝트 3)

### 7. 향후 고려사항

*   프로젝트 3에서 진행될 API 서비스 구축을 위한 최종 모델을 제공합니다.
*   데이터 증강 기법의 다양화 및 고급 앙상블 기법(예: 스태킹) 적용을 통해 모델 성능을 더욱 향상시킬 수 있습니다.
